require('dotenv').config({ path: '../.env' });
console.log('VRF_SECRET_KEY from .env:', process.env.VRF_SECRET_KEY);

const pool = require('../backend/database');
const vrfHandler = require('./vrfHandler');

async function processNewData() {
    console.log('ğŸš€ Starting processData.js');
    console.log('ğŸ”„ Running VRF Batch Processing...');

    const newSegments = [
        { "temperature": 40, "humidity": 80 }
    ];

    console.log(`ğŸ“¦ Segments to process: ${newSegments.length}`);

    for (const segment of newSegments) {
        console.log(`ğŸ” Generating VRF for segment:`, segment);

        const { segmentHash, fingerprint, secretKey } = await vrfHandler.generateVRF(segment);
        console.log("âœ… VRF Output:", { segmentHash, fingerprint, secretKey });

        const existing = await pool.query(
            'SELECT * FROM time_series_vrf WHERE segment_hash = $1',
            [segmentHash]
        );

        if (existing.rows.length > 0) {
            console.log(`âš ï¸ Skipping duplicate segment: ${segmentHash}`);
            continue;
        }

        console.log(`ğŸ“ Storing VRF data in PostgreSQL...`);

        await pool.query(
            'INSERT INTO time_series_vrf (segment_hash, vrf_fingerprint, secret_key) VALUES ($1, $2, $3)',
            [segmentHash, fingerprint, secretKey]
        );

        console.log(`âœ… Processed Segment: ${segmentHash}`);
    }
}

processNewData().catch((err) => {
    console.error("âŒ Error in processing data:", err);
});