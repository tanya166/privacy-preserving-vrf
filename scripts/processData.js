require('dotenv').config({ path: '../.env' });
const pool = require('../backend/database');
const vrfHandler = require('./vrfHandler');
const { ethers } = require('ethers');
const fs = require('fs');
const path = require('path');

const CONTRACT_ABI = [
    "function storeFingerprint(bytes32 segmentHash, bytes32 vrfFingerprint) public",
    "function verifyFingerprint(bytes32 segmentHash, bytes32 claimedFingerprint) public view returns (bool)",
    "function getFingerprint(bytes32 segmentHash) public view returns (bytes32 vrfFingerprint, uint256 timestamp, bool exists)",
    "function fingerprintExists(bytes32 segmentHash) public view returns (bool)"
];

async function initializeContract(contractAddress, privateKey, rpcUrl) {
    const provider = new ethers.JsonRpcProvider(rpcUrl);
    const wallet = new ethers.Wallet(privateKey, provider);
    const contract = new ethers.Contract(contractAddress, CONTRACT_ABI, wallet);
    return contract;
}

function loadDataFromFile(filePath) {
    try {
       
        if (!fs.existsSync(filePath)) {
            throw new Error(`File not found: ${filePath}`);
        }

       
        const fileContent = fs.readFileSync(filePath, 'utf8');
        const jsonData = JSON.parse(fileContent);
        
        
        const dataArray = Array.isArray(jsonData) ? jsonData : [jsonData];
        
        console.log(`üìÑ Loaded ${dataArray.length} data segments from: ${filePath}`);
        return dataArray;
        
    } catch (error) {
        throw new Error(`Failed to load data from file: ${error.message}`);
    }
}

async function processData(dataSegments, contractAddress, privateKey, rpcUrl, vrfPrivateKey = null) {
    console.log('üîÑ Running VRF Batch Processing...');
    
    const useCustomVRFKey = vrfPrivateKey !== null;
    
    if (useCustomVRFKey) {
        console.log('üîë Using custom VRF private key');
    } else {
        console.log('üîë Using environment VRF key (.env file)');
    }

    const contract = await initializeContract(contractAddress, privateKey, rpcUrl);

    console.log(`üì¶ Segments to process: ${dataSegments.length}`);

    let processedCount = 0;
    let skippedCount = 0;
    let errorCount = 0;
    const results = [];
    const errors = [];

    for (let i = 0; i < dataSegments.length; i++) {
        const segment = dataSegments[i];
        console.log(`\nüîê Processing segment ${i + 1}/${dataSegments.length}:`, segment);

        try {
            let vrfResult;
            
            if (useCustomVRFKey) {
                vrfResult = await vrfHandler.generateVRFWithKey(segment, vrfPrivateKey);
            } else {
                vrfResult = await vrfHandler.generateVRF(segment);
            }
            
            const { segmentHash, fingerprint, secretKey, walletAddress } = vrfResult;
            
            console.log("‚úÖ VRF Output:", { 
                segmentHash, 
                fingerprint: fingerprint.substring(0, 10) + '...', 
                walletAddress: walletAddress || 'N/A',
                secretKey: secretKey.substring(0, 10) + '...' 
            });

           
            const hashedFingerprint = ethers.keccak256(fingerprint);
            console.log(`üî® Converted fingerprint from ${fingerprint.length - 2} chars to 32 bytes: ${hashedFingerprint}`);

            const existing = await pool.query(
                'SELECT * FROM time_series_vrf WHERE segment_hash = $1',
                [segmentHash]
            );

            if (existing.rows.length > 0) {
                console.log(`‚ö†Ô∏è Skipping duplicate segment: ${segmentHash}`);
                skippedCount++;
                
                results.push({
                    segment,
                    segmentHash,
                    status: 'ALREADY_EXISTS',
                    message: 'Data already stored'
                });
                continue;
            }

            console.log(`üìù Storing VRF data in PostgreSQL...`);
            
            await pool.query(
                'INSERT INTO time_series_vrf (segment_hash, vrf_fingerprint, secret_key) VALUES ($1, $2, $3)',
                [segmentHash, fingerprint, secretKey]
            );

            console.log(`üîó Storing VRF fingerprint in smart contract...`);
            
            const tx = await contract.storeFingerprint(segmentHash, hashedFingerprint);
            console.log(`‚è≥ Transaction sent: ${tx.hash}`);
            
            const receipt = await tx.wait();
            console.log(`‚úÖ Transaction confirmed in block: ${receipt.blockNumber}`);

            console.log(`‚úÖ Processed Segment: ${segmentHash}`);
            processedCount++;
            
            results.push({
                segment,
                segmentHash,
                originalFingerprint: fingerprint,
                hashedFingerprint,
                transactionHash: tx.hash,
                blockNumber: receipt.blockNumber,
                gasUsed: receipt.gasUsed.toString(),
                status: 'SUCCESS',
                message: 'Data successfully stored on blockchain'
            });

        } catch (error) {
            console.error(`‚ùå Error processing segment ${i + 1}:`, error);
            errorCount++;
            
            try {
                let vrfResult;
                if (useCustomVRFKey) {
                    vrfResult = await vrfHandler.generateVRFWithKey(segment, vrfPrivateKey);
                } else {
                    vrfResult = await vrfHandler.generateVRF(segment);
                }
                
                await pool.query('DELETE FROM time_series_vrf WHERE segment_hash = $1', [vrfResult.segmentHash]);
                console.log(`üîÑ Rolled back database entry for ${vrfResult.segmentHash}`);
            } catch (rollbackError) {
                console.error(`‚ùå Failed to rollback database entry:`, rollbackError);
            }
            
            errors.push({
                segment,
                error: error.message,
                index: i + 1
            });
        }
    }

    console.log('\nüìä Processing Summary:');
    console.log(`   Total segments: ${dataSegments.length}`);
    console.log(`   Successfully processed: ${processedCount}`);
    console.log(`   Skipped (duplicates): ${skippedCount}`);
    console.log(`   Errors: ${errorCount}`);
    console.log('üéâ Batch processing completed!');
    
    return {
        success: errorCount === 0,
        summary: {
            total: dataSegments.length,
            successful: processedCount,
            skipped: skippedCount,
            errors: errorCount
        },
        results,
        errors: errors.length > 0 ? errors : undefined
    };
}

async function processNewDataFromFile() {
    console.log('üöÄ Starting processData.js from command line');
    
    const CONTRACT_ADDRESS = process.env.CONTRACT_ADDRESS;
    const PRIVATE_KEY = process.env.PRIVATE_KEY;
    const RPC_URL = process.env.POLYGON_RPC;
    
    console.log('üîç Environment check:');
    console.log('CONTRACT_ADDRESS:', CONTRACT_ADDRESS);
    console.log('RPC_URL:', RPC_URL);
    console.log('PRIVATE_KEY:', PRIVATE_KEY ? 'defined' : 'undefined');

    if (!CONTRACT_ADDRESS || !PRIVATE_KEY || !RPC_URL) {
        console.error('‚ùå Missing required environment variables: CONTRACT_ADDRESS, PRIVATE_KEY, POLYGON_RPC');
        process.exit(1);
    }


    const jsonFilePath = process.argv[2] || path.join(__dirname, 'data.json');
    
    let newSegments;
    try {
        newSegments = loadDataFromFile(jsonFilePath);
    } catch (error) {
        console.error('‚ùå Failed to load data:', error.message);
        console.log('üí° Usage: node processData.js [path/to/your/data.json]');
        console.log('üí° Or create a "data.json" file in the same directory as this script');
        process.exit(1);
    }

    try {
        const result = await processData(newSegments, CONTRACT_ADDRESS, PRIVATE_KEY, RPC_URL);
        
        if (result.success) {
            console.log('üéâ All data processed successfully!');
            process.exit(0);
        } else {
            console.log(`‚ö†Ô∏è Processing completed with ${result.summary.errors} errors`);
            process.exit(1);
        }
    } catch (error) {
        console.error("‚ùå Fatal error in processing data:", error);
        process.exit(1);
    }
}

module.exports = {
    processData,           
    loadDataFromFile,      
    initializeContract     
};

if (require.main === module) {
    processNewDataFromFile().catch((err) => {
        console.error("‚ùå Error in processing data:", err);
        process.exit(1);
    });
}